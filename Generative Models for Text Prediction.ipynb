{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) b) Using all 4 books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)  i) Files are concatenated in 'Part1.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('Part1.txt',encoding='utf-8').read()\n",
    "file = file.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(file)))\n",
    "c2i = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) ii) Using ASCII encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  1483924\n",
      "Total Vocab:  98\n"
     ]
    }
   ],
   "source": [
    "no_of_chars = len(file)\n",
    "no_of_vocab = len(chars)\n",
    "print (\"Total Characters: \", no_of_chars)\n",
    "print (\"Total Vocab: \", no_of_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) iii) Using window size 99\n",
    "### c) iv) Inputs to the network will be the first W âˆ’ 1 charachters in each sequence\n",
    "### c) v) Output encoded using one-hot encoding scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  1595678\n"
     ]
    }
   ],
   "source": [
    "win_size = 99\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - win_size, 1):\n",
    "    try:\n",
    "        seq_in = file[i:i + win_size]\n",
    "        seq_out = file[i + win_size]\n",
    "    except:\n",
    "        continue\n",
    "    dataX.append([c2i[char] for char in seq_in])\n",
    "    dataY.append(c2i[seq_out])\n",
    "no_of_patterns = len(dataX)\n",
    "print (\"Total Patterns: \", n_patterns)\n",
    "X = numpy.reshape(dataX, (no_of_patterns, win_size, 1))\n",
    "X = X / float(n_vocab)\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) vi) Using a single hidden layer (N = 256)\n",
    "### c) vii) Using a softmax output layer\n",
    "### c) viii) No test data set being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) ix) As per available computational power, 15 epochs chosen\n",
    "### c) x) Using model checkpoint to save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_file=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(weights_file, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1483825/1483825 [==============================] - 4060s 3ms/step - loss: 2.7473\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.74727, saving model to weights-improvement-01-2.7473.hdf5\n",
      "Epoch 2/15\n",
      "1483825/1483825 [==============================] - 3952s 3ms/step - loss: 2.4682\n",
      "\n",
      "Epoch 00002: loss improved from 2.74727 to 2.46819, saving model to weights-improvement-02-2.4682.hdf5\n",
      "Epoch 3/15\n",
      "1483825/1483825 [==============================] - 3444s 2ms/step - loss: 2.2829\n",
      "\n",
      "Epoch 00003: loss improved from 2.46819 to 2.28291, saving model to weights-improvement-03-2.2829.hdf5\n",
      "Epoch 4/15\n",
      "1483825/1483825 [==============================] - 3337s 2ms/step - loss: 2.1634\n",
      "\n",
      "Epoch 00004: loss improved from 2.28291 to 2.16335, saving model to weights-improvement-04-2.1634.hdf5\n",
      "Epoch 5/15\n",
      "1483825/1483825 [==============================] - 3514s 2ms/step - loss: 2.0820\n",
      "\n",
      "Epoch 00005: loss improved from 2.16335 to 2.08204, saving model to weights-improvement-05-2.0820.hdf5\n",
      "Epoch 6/15\n",
      "1483825/1483825 [==============================] - 3567s 2ms/step - loss: 2.0220\n",
      "\n",
      "Epoch 00006: loss improved from 2.08204 to 2.02202, saving model to weights-improvement-06-2.0220.hdf5\n",
      "Epoch 7/15\n",
      "1483825/1483825 [==============================] - 3412s 2ms/step - loss: 1.9774\n",
      "\n",
      "Epoch 00007: loss improved from 2.02202 to 1.97740, saving model to weights-improvement-07-1.9774.hdf5\n",
      "Epoch 8/15\n",
      "1483825/1483825 [==============================] - 3345s 2ms/step - loss: 1.9408\n",
      "\n",
      "Epoch 00008: loss improved from 1.97740 to 1.94081, saving model to weights-improvement-08-1.9408.hdf5\n",
      "Epoch 9/15\n",
      "1483825/1483825 [==============================] - 3307s 2ms/step - loss: 1.9113\n",
      "\n",
      "Epoch 00009: loss improved from 1.94081 to 1.91125, saving model to weights-improvement-09-1.9113.hdf5\n",
      "Epoch 10/15\n",
      "1483825/1483825 [==============================] - 3281s 2ms/step - loss: 1.8858\n",
      "\n",
      "Epoch 00010: loss improved from 1.91125 to 1.88582, saving model to weights-improvement-10-1.8858.hdf5\n",
      "Epoch 11/15\n",
      "1483825/1483825 [==============================] - 3258s 2ms/step - loss: 1.9015\n",
      "\n",
      "Epoch 00011: loss did not improve from 1.88582\n",
      "Epoch 12/15\n",
      "1483825/1483825 [==============================] - 3239s 2ms/step - loss: 2.6651\n",
      "\n",
      "Epoch 00012: loss did not improve from 1.88582\n",
      "Epoch 13/15\n",
      "1483825/1483825 [==============================] - 3215s 2ms/step - loss: 2.2581\n",
      "\n",
      "Epoch 00013: loss did not improve from 1.88582\n",
      "Epoch 14/15\n",
      "1483825/1483825 [==============================] - 3217s 2ms/step - loss: 1.9431\n",
      "\n",
      "Epoch 00014: loss did not improve from 1.88582\n",
      "Epoch 15/15\n",
      "1483825/1483825 [==============================] - 3226s 2ms/step - loss: 1.8718\n",
      "\n",
      "Epoch 00015: loss improved from 1.88582 to 1.87184, saving model to weights-improvement-15-1.8718.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12a67d5c0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=15, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) xi) Generating text using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n"
     ]
    }
   ],
   "source": [
    "seed_sentence = [c2i[char] for char in \"there are those who take mental phenomena naively, just as they would physical phenomena. this school of psychologists tends not to emphasize the object.\"]\n",
    "print(len(seed_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ouput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nelic and the poents of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of the seisn of t"
     ]
    }
   ],
   "source": [
    "pattern = seed_sentence[0:99]\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(no_of_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference:\n",
    "- We can see how the LSTM is repeating the words, this can mean:\n",
    " - The number of books were less\n",
    " - The number were epcohs were less\n",
    " - On using more of both of the above, we can definitely get better results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
